{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BreastCancerData (4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BreastFeeding</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>BreastCancerHistory</th>\n",
       "      <th>Age at firstPeriod</th>\n",
       "      <th>MenstrualCycle</th>\n",
       "      <th>Cancer Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>8.543723</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>10.204207</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>13.807133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>14.088867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>14.494061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  BreastFeeding  Marital Status  Alcohol  Smoking  \\\n",
       "0   48   8.543723              1               1        0        0   \n",
       "1   31  10.204207              1               1        0        0   \n",
       "2   31  13.807133              1               1        0        0   \n",
       "3   33  14.088867              1               1        1        0   \n",
       "4   49  14.494061              1               1        0        0   \n",
       "\n",
       "   BreastCancerHistory  Age at firstPeriod  MenstrualCycle  Cancer Positive  \n",
       "0                    0                  15               1                0  \n",
       "1                    0                  12               1                0  \n",
       "2                    0                  14               1                0  \n",
       "3                    0                  12               1                0  \n",
       "4                    0                  15               1                0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>41.029313</td>\n",
       "      <td>7.694522</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BMI</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>24.723056</td>\n",
       "      <td>4.939623</td>\n",
       "      <td>8.543723</td>\n",
       "      <td>21.168699</td>\n",
       "      <td>24.453841</td>\n",
       "      <td>27.657793</td>\n",
       "      <td>69.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BreastFeeding</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.891122</td>\n",
       "      <td>0.311551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Marital Status</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>1.126466</td>\n",
       "      <td>0.455754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Alcohol</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.351340</td>\n",
       "      <td>0.477489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Smoking</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.154941</td>\n",
       "      <td>0.361925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BreastCancerHistory</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.029313</td>\n",
       "      <td>0.168718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age at firstPeriod</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>13.104690</td>\n",
       "      <td>1.684577</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MenstrualCycle</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.781826</td>\n",
       "      <td>0.413093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Cancer Positive</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.404523</td>\n",
       "      <td>0.490902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count       mean       std        min        25%  \\\n",
       "Age                  2388.0  41.029313  7.694522  21.000000  35.000000   \n",
       "BMI                  2388.0  24.723056  4.939623   8.543723  21.168699   \n",
       "BreastFeeding        2388.0   0.891122  0.311551   0.000000   1.000000   \n",
       "Marital Status       2388.0   1.126466  0.455754   1.000000   1.000000   \n",
       "Alcohol              2388.0   0.351340  0.477489   0.000000   0.000000   \n",
       "Smoking              2388.0   0.154941  0.361925   0.000000   0.000000   \n",
       "BreastCancerHistory  2388.0   0.029313  0.168718   0.000000   0.000000   \n",
       "Age at firstPeriod   2388.0  13.104690  1.684577   8.000000  12.000000   \n",
       "MenstrualCycle       2388.0   0.781826  0.413093   0.000000   1.000000   \n",
       "Cancer Positive      2388.0   0.404523  0.490902   0.000000   0.000000   \n",
       "\n",
       "                           50%        75%   max  \n",
       "Age                  41.000000  48.000000  54.0  \n",
       "BMI                  24.453841  27.657793  69.5  \n",
       "BreastFeeding         1.000000   1.000000   1.0  \n",
       "Marital Status        1.000000   1.000000   3.0  \n",
       "Alcohol               0.000000   1.000000   1.0  \n",
       "Smoking               0.000000   0.000000   1.0  \n",
       "BreastCancerHistory   0.000000   0.000000   1.0  \n",
       "Age at firstPeriod   13.000000  14.000000  21.0  \n",
       "MenstrualCycle        1.000000   1.000000   1.0  \n",
       "Cancer Positive       0.000000   1.000000   1.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2388 entries, 0 to 2387\n",
      "Data columns (total 10 columns):\n",
      "Age                    2388 non-null int64\n",
      "BMI                    2388 non-null float64\n",
      "BreastFeeding          2388 non-null int64\n",
      "Marital Status         2388 non-null int64\n",
      "Alcohol                2388 non-null int64\n",
      "Smoking                2388 non-null int64\n",
      "BreastCancerHistory    2388 non-null int64\n",
      "Age at firstPeriod     2388 non-null int64\n",
      "MenstrualCycle         2388 non-null int64\n",
      "Cancer Positive        2388 non-null int64\n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 186.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17060799e08>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Cancer Positive',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MenstrualCycle        -0.527303\n",
       "Age at firstPeriod    -0.143939\n",
       "BreastFeeding         -0.125521\n",
       "Alcohol                0.040402\n",
       "Smoking                0.047929\n",
       "BreastCancerHistory    0.145085\n",
       "Marital Status         0.230007\n",
       "BMI                    0.360163\n",
       "Age                    0.387485\n",
       "Name: Cancer Positive, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['Cancer Positive'][:-1].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Cancer Positive',axis=1).values\n",
    "y = df['Cancer Positive'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48.        ,  8.5437225 ,  1.        , ...,  0.        ,\n",
       "        15.        ,  1.        ],\n",
       "       [31.        , 10.20420723,  1.        , ...,  0.        ,\n",
       "        12.        ,  1.        ],\n",
       "       [31.        , 13.80713296,  1.        , ...,  0.        ,\n",
       "        14.        ,  1.        ],\n",
       "       ...,\n",
       "       [51.        , 44.17113007,  0.        , ...,  1.        ,\n",
       "        14.        ,  0.        ],\n",
       "       [41.        , 57.76097459,  1.        , ...,  0.        ,\n",
       "        13.        ,  1.        ],\n",
       "       [35.        , 69.5       ,  1.        , ...,  1.        ,\n",
       "        15.        ,  1.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2388, 9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2388,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1791, 9)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(9,activation='relu',input_shape=(9, )))\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1791 samples, validate on 597 samples\n",
      "Epoch 1/1000\n",
      "1791/1791 [==============================] - 1s 496us/sample - loss: 0.7127 - val_loss: 0.7007\n",
      "Epoch 2/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.6882 - val_loss: 0.6821\n",
      "Epoch 3/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.6703 - val_loss: 0.6683\n",
      "Epoch 4/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.667 - 0s 37us/sample - loss: 0.6571 - val_loss: 0.6570\n",
      "Epoch 5/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.6469 - val_loss: 0.6458\n",
      "Epoch 6/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.6369 - val_loss: 0.6346\n",
      "Epoch 7/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.6273 - val_loss: 0.6237\n",
      "Epoch 8/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.6183 - val_loss: 0.6139\n",
      "Epoch 9/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.6091 - val_loss: 0.6043\n",
      "Epoch 10/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.6008 - val_loss: 0.5946\n",
      "Epoch 11/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.5924 - val_loss: 0.5853\n",
      "Epoch 12/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.5846 - val_loss: 0.5766\n",
      "Epoch 13/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.5766 - val_loss: 0.5673\n",
      "Epoch 14/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.5669 - val_loss: 0.5542\n",
      "Epoch 15/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.5553 - val_loss: 0.5412\n",
      "Epoch 16/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.5434 - val_loss: 0.5284\n",
      "Epoch 17/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.5310 - val_loss: 0.5148\n",
      "Epoch 18/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.5181 - val_loss: 0.4989\n",
      "Epoch 19/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.5018 - val_loss: 0.4806\n",
      "Epoch 20/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4867 - val_loss: 0.4650\n",
      "Epoch 21/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4750 - val_loss: 0.4523\n",
      "Epoch 22/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4647 - val_loss: 0.4423\n",
      "Epoch 23/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.4567 - val_loss: 0.4334\n",
      "Epoch 24/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4493 - val_loss: 0.4258\n",
      "Epoch 25/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.4440 - val_loss: 0.4200\n",
      "Epoch 26/1000\n",
      "1791/1791 [==============================] - 0s 42us/sample - loss: 0.4372 - val_loss: 0.4136\n",
      "Epoch 27/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.4324 - val_loss: 0.4087\n",
      "Epoch 28/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4278 - val_loss: 0.4039\n",
      "Epoch 29/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.4238 - val_loss: 0.3995\n",
      "Epoch 30/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.4199 - val_loss: 0.3950\n",
      "Epoch 31/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4159 - val_loss: 0.3919\n",
      "Epoch 32/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.4130 - val_loss: 0.3878\n",
      "Epoch 33/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.4094 - val_loss: 0.3852\n",
      "Epoch 34/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4056 - val_loss: 0.3819\n",
      "Epoch 35/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.4022 - val_loss: 0.3794\n",
      "Epoch 36/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.4028 - val_loss: 0.3756\n",
      "Epoch 37/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3986 - val_loss: 0.3734\n",
      "Epoch 38/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3934 - val_loss: 0.3707\n",
      "Epoch 39/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.3904 - val_loss: 0.3678\n",
      "Epoch 40/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3887 - val_loss: 0.3660\n",
      "Epoch 41/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3860 - val_loss: 0.3633\n",
      "Epoch 42/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3833 - val_loss: 0.3609\n",
      "Epoch 43/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.3815 - val_loss: 0.3582\n",
      "Epoch 44/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3792 - val_loss: 0.3563\n",
      "Epoch 45/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3762 - val_loss: 0.3548\n",
      "Epoch 46/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3741 - val_loss: 0.3518\n",
      "Epoch 47/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.334 - 0s 30us/sample - loss: 0.3717 - val_loss: 0.3501\n",
      "Epoch 48/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3693 - val_loss: 0.3479\n",
      "Epoch 49/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3673 - val_loss: 0.3459\n",
      "Epoch 50/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3663 - val_loss: 0.3458\n",
      "Epoch 51/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3665 - val_loss: 0.3431\n",
      "Epoch 52/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3640 - val_loss: 0.3430\n",
      "Epoch 53/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3617 - val_loss: 0.3401\n",
      "Epoch 54/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3599 - val_loss: 0.3393\n",
      "Epoch 55/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3579 - val_loss: 0.3384\n",
      "Epoch 56/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3573 - val_loss: 0.3365\n",
      "Epoch 57/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3562 - val_loss: 0.3372\n",
      "Epoch 58/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3544 - val_loss: 0.3345\n",
      "Epoch 59/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3546 - val_loss: 0.3351\n",
      "Epoch 60/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.3539 - val_loss: 0.3332\n",
      "Epoch 61/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.3527 - val_loss: 0.3339\n",
      "Epoch 62/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3512 - val_loss: 0.3314\n",
      "Epoch 63/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3496 - val_loss: 0.3308\n",
      "Epoch 64/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3480 - val_loss: 0.3304\n",
      "Epoch 65/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3469 - val_loss: 0.3288\n",
      "Epoch 66/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3468 - val_loss: 0.3273\n",
      "Epoch 67/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3457 - val_loss: 0.3267\n",
      "Epoch 68/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3442 - val_loss: 0.3276\n",
      "Epoch 69/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3436 - val_loss: 0.3257\n",
      "Epoch 70/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3424 - val_loss: 0.3252\n",
      "Epoch 71/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3412 - val_loss: 0.3243\n",
      "Epoch 72/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3401 - val_loss: 0.3250\n",
      "Epoch 73/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3396 - val_loss: 0.3246\n",
      "Epoch 74/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3386 - val_loss: 0.3222\n",
      "Epoch 75/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3374 - val_loss: 0.3243\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3379 - val_loss: 0.3229\n",
      "Epoch 77/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3366 - val_loss: 0.3212\n",
      "Epoch 78/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3361 - val_loss: 0.3212\n",
      "Epoch 79/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3351 - val_loss: 0.3216\n",
      "Epoch 80/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3339 - val_loss: 0.3193\n",
      "Epoch 81/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3338 - val_loss: 0.3252\n",
      "Epoch 82/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3341 - val_loss: 0.3185\n",
      "Epoch 83/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3337 - val_loss: 0.3181\n",
      "Epoch 84/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3336 - val_loss: 0.3211\n",
      "Epoch 85/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3313 - val_loss: 0.3168\n",
      "Epoch 86/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3303 - val_loss: 0.3190\n",
      "Epoch 87/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3301 - val_loss: 0.3175\n",
      "Epoch 88/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3291 - val_loss: 0.3170\n",
      "Epoch 89/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3289 - val_loss: 0.3186\n",
      "Epoch 90/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3282 - val_loss: 0.3157\n",
      "Epoch 91/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3276 - val_loss: 0.3162\n",
      "Epoch 92/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3280 - val_loss: 0.3167\n",
      "Epoch 93/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3263 - val_loss: 0.3140\n",
      "Epoch 94/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3264 - val_loss: 0.3151\n",
      "Epoch 95/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3259 - val_loss: 0.3146\n",
      "Epoch 96/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3251 - val_loss: 0.3148\n",
      "Epoch 97/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3244 - val_loss: 0.3134\n",
      "Epoch 98/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3241 - val_loss: 0.3140\n",
      "Epoch 99/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3239 - val_loss: 0.3147\n",
      "Epoch 100/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3237 - val_loss: 0.3149\n",
      "Epoch 101/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3231 - val_loss: 0.3135\n",
      "Epoch 102/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3237 - val_loss: 0.3142\n",
      "Epoch 103/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3226 - val_loss: 0.3126\n",
      "Epoch 104/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3232 - val_loss: 0.3107\n",
      "Epoch 105/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3244 - val_loss: 0.3178\n",
      "Epoch 106/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3227 - val_loss: 0.3101\n",
      "Epoch 107/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3210 - val_loss: 0.3133\n",
      "Epoch 108/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3195 - val_loss: 0.3107\n",
      "Epoch 109/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3199 - val_loss: 0.3095\n",
      "Epoch 110/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3188 - val_loss: 0.3114\n",
      "Epoch 111/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3188 - val_loss: 0.3099\n",
      "Epoch 112/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3181 - val_loss: 0.3104\n",
      "Epoch 113/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3180 - val_loss: 0.3109\n",
      "Epoch 114/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3180 - val_loss: 0.3078\n",
      "Epoch 115/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3169 - val_loss: 0.3095\n",
      "Epoch 116/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3159 - val_loss: 0.3081\n",
      "Epoch 117/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3155 - val_loss: 0.3093\n",
      "Epoch 118/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3151 - val_loss: 0.3083\n",
      "Epoch 119/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3148 - val_loss: 0.3073\n",
      "Epoch 120/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3149 - val_loss: 0.3091\n",
      "Epoch 121/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3134 - val_loss: 0.3064\n",
      "Epoch 122/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3136 - val_loss: 0.3068\n",
      "Epoch 123/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3141 - val_loss: 0.3081\n",
      "Epoch 124/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3124 - val_loss: 0.3061\n",
      "Epoch 125/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3130 - val_loss: 0.3050\n",
      "Epoch 126/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3121 - val_loss: 0.3060\n",
      "Epoch 127/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3115 - val_loss: 0.3042\n",
      "Epoch 128/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3102 - val_loss: 0.3055\n",
      "Epoch 129/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3097 - val_loss: 0.3055\n",
      "Epoch 130/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3092 - val_loss: 0.3052\n",
      "Epoch 131/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3087 - val_loss: 0.3026\n",
      "Epoch 132/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3077 - val_loss: 0.3062\n",
      "Epoch 133/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3077 - val_loss: 0.3037\n",
      "Epoch 134/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.3068 - val_loss: 0.3030\n",
      "Epoch 135/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3060 - val_loss: 0.3020\n",
      "Epoch 136/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3074 - val_loss: 0.2997\n",
      "Epoch 137/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3055 - val_loss: 0.3048\n",
      "Epoch 138/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3045 - val_loss: 0.3003\n",
      "Epoch 139/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.3040 - val_loss: 0.2998\n",
      "Epoch 140/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3038 - val_loss: 0.2995\n",
      "Epoch 141/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.3035 - val_loss: 0.3012\n",
      "Epoch 142/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3023 - val_loss: 0.2991\n",
      "Epoch 143/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3020 - val_loss: 0.2997\n",
      "Epoch 144/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3018 - val_loss: 0.3013\n",
      "Epoch 145/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3017 - val_loss: 0.2978\n",
      "Epoch 146/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3006 - val_loss: 0.2991\n",
      "Epoch 147/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3004 - val_loss: 0.2962\n",
      "Epoch 148/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2996 - val_loss: 0.3022\n",
      "Epoch 149/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2987 - val_loss: 0.2960\n",
      "Epoch 150/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2974 - val_loss: 0.3003\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2964 - val_loss: 0.2963\n",
      "Epoch 152/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2959 - val_loss: 0.2984\n",
      "Epoch 153/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2955 - val_loss: 0.2960\n",
      "Epoch 154/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2960 - val_loss: 0.2989\n",
      "Epoch 155/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2943 - val_loss: 0.2948\n",
      "Epoch 156/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2941 - val_loss: 0.2976\n",
      "Epoch 157/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2930 - val_loss: 0.2955\n",
      "Epoch 158/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2923 - val_loss: 0.2956\n",
      "Epoch 159/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2918 - val_loss: 0.2936\n",
      "Epoch 160/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2914 - val_loss: 0.2942\n",
      "Epoch 161/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2903 - val_loss: 0.2957\n",
      "Epoch 162/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2898 - val_loss: 0.2934\n",
      "Epoch 163/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2897 - val_loss: 0.2940\n",
      "Epoch 164/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2896 - val_loss: 0.2922\n",
      "Epoch 165/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2889 - val_loss: 0.2926\n",
      "Epoch 166/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2877 - val_loss: 0.2922\n",
      "Epoch 167/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2876 - val_loss: 0.2903\n",
      "Epoch 168/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2863 - val_loss: 0.2931\n",
      "Epoch 169/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2859 - val_loss: 0.2915\n",
      "Epoch 170/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2854 - val_loss: 0.2920\n",
      "Epoch 171/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2847 - val_loss: 0.2906\n",
      "Epoch 172/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2842 - val_loss: 0.2918\n",
      "Epoch 173/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2843 - val_loss: 0.2882\n",
      "Epoch 174/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2840 - val_loss: 0.2887\n",
      "Epoch 175/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2831 - val_loss: 0.2915\n",
      "Epoch 176/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2826 - val_loss: 0.2883\n",
      "Epoch 177/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.2820 - val_loss: 0.2900\n",
      "Epoch 178/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2816 - val_loss: 0.2877\n",
      "Epoch 179/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2811 - val_loss: 0.2867\n",
      "Epoch 180/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2804 - val_loss: 0.2888\n",
      "Epoch 181/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2822 - val_loss: 0.2850\n",
      "Epoch 182/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2802 - val_loss: 0.2885\n",
      "Epoch 183/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2791 - val_loss: 0.2864\n",
      "Epoch 184/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2787 - val_loss: 0.2844\n",
      "Epoch 185/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2790 - val_loss: 0.2847\n",
      "Epoch 186/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2776 - val_loss: 0.2850\n",
      "Epoch 187/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2776 - val_loss: 0.2867\n",
      "Epoch 188/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2776 - val_loss: 0.2868\n",
      "Epoch 189/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2766 - val_loss: 0.2847\n",
      "Epoch 190/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2763 - val_loss: 0.2840\n",
      "Epoch 191/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2756 - val_loss: 0.2845\n",
      "Epoch 192/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2751 - val_loss: 0.2836\n",
      "Epoch 193/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2751 - val_loss: 0.2838\n",
      "Epoch 194/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2747 - val_loss: 0.2814\n",
      "Epoch 195/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2736 - val_loss: 0.2860\n",
      "Epoch 196/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2739 - val_loss: 0.2796\n",
      "Epoch 197/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2746 - val_loss: 0.2829\n",
      "Epoch 198/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2725 - val_loss: 0.2792\n",
      "Epoch 199/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.2733 - val_loss: 0.2852\n",
      "Epoch 200/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2720 - val_loss: 0.2788\n",
      "Epoch 201/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2714 - val_loss: 0.2811\n",
      "Epoch 202/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2713 - val_loss: 0.2827\n",
      "Epoch 203/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2710 - val_loss: 0.2814\n",
      "Epoch 204/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2703 - val_loss: 0.2787\n",
      "Epoch 205/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2696 - val_loss: 0.2787\n",
      "Epoch 206/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2691 - val_loss: 0.2800\n",
      "Epoch 207/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2688 - val_loss: 0.2785\n",
      "Epoch 208/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2679 - val_loss: 0.2788\n",
      "Epoch 209/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2681 - val_loss: 0.2797\n",
      "Epoch 210/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2680 - val_loss: 0.2758\n",
      "Epoch 211/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2671 - val_loss: 0.2799\n",
      "Epoch 212/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2666 - val_loss: 0.2763\n",
      "Epoch 213/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2670 - val_loss: 0.2763\n",
      "Epoch 214/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2658 - val_loss: 0.2758\n",
      "Epoch 215/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2659 - val_loss: 0.2746\n",
      "Epoch 216/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2658 - val_loss: 0.2812\n",
      "Epoch 217/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2672 - val_loss: 0.2806\n",
      "Epoch 218/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2660 - val_loss: 0.2732\n",
      "Epoch 219/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2655 - val_loss: 0.2840\n",
      "Epoch 220/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2644 - val_loss: 0.2724\n",
      "Epoch 221/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2644 - val_loss: 0.2793\n",
      "Epoch 222/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2630 - val_loss: 0.2735\n",
      "Epoch 223/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2631 - val_loss: 0.2726\n",
      "Epoch 224/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2624 - val_loss: 0.2780\n",
      "Epoch 225/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2639 - val_loss: 0.2709\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2626 - val_loss: 0.2732\n",
      "Epoch 227/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2611 - val_loss: 0.2753\n",
      "Epoch 228/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2603 - val_loss: 0.2717\n",
      "Epoch 229/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2606 - val_loss: 0.2748\n",
      "Epoch 230/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2604 - val_loss: 0.2738\n",
      "Epoch 231/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2609 - val_loss: 0.2693\n",
      "Epoch 232/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2606 - val_loss: 0.2737\n",
      "Epoch 233/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2596 - val_loss: 0.2718\n",
      "Epoch 234/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2590 - val_loss: 0.2708\n",
      "Epoch 235/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2585 - val_loss: 0.2725\n",
      "Epoch 236/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2591 - val_loss: 0.2738\n",
      "Epoch 237/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2583 - val_loss: 0.2705\n",
      "Epoch 238/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2567 - val_loss: 0.2713\n",
      "Epoch 239/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2566 - val_loss: 0.2685\n",
      "Epoch 240/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2574 - val_loss: 0.2741\n",
      "Epoch 241/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2564 - val_loss: 0.2674\n",
      "Epoch 242/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2552 - val_loss: 0.2686\n",
      "Epoch 243/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2552 - val_loss: 0.2715\n",
      "Epoch 244/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2552 - val_loss: 0.2652\n",
      "Epoch 245/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2558 - val_loss: 0.2704\n",
      "Epoch 246/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2542 - val_loss: 0.2646\n",
      "Epoch 247/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2562 - val_loss: 0.2752\n",
      "Epoch 248/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2528 - val_loss: 0.2644\n",
      "Epoch 249/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2528 - val_loss: 0.2695\n",
      "Epoch 250/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2532 - val_loss: 0.2678\n",
      "Epoch 251/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2526 - val_loss: 0.2696\n",
      "Epoch 252/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2516 - val_loss: 0.2646\n",
      "Epoch 253/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2560 - val_loss: 0.2764\n",
      "Epoch 254/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2547 - val_loss: 0.2653\n",
      "Epoch 255/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2507 - val_loss: 0.2663\n",
      "Epoch 256/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2506 - val_loss: 0.2668\n",
      "Epoch 257/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2508 - val_loss: 0.2652\n",
      "Epoch 258/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2496 - val_loss: 0.2637\n",
      "Epoch 259/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2513 - val_loss: 0.2641\n",
      "Epoch 260/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2489 - val_loss: 0.2637\n",
      "Epoch 261/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2494 - val_loss: 0.2640\n",
      "Epoch 262/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2494 - val_loss: 0.2711\n",
      "Epoch 263/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2500 - val_loss: 0.2618\n",
      "Epoch 264/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2480 - val_loss: 0.2646\n",
      "Epoch 265/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2489 - val_loss: 0.2669\n",
      "Epoch 266/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2489 - val_loss: 0.2622\n",
      "Epoch 267/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2468 - val_loss: 0.2638\n",
      "Epoch 268/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2462 - val_loss: 0.2623\n",
      "Epoch 269/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2464 - val_loss: 0.2660\n",
      "Epoch 270/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2473 - val_loss: 0.2614\n",
      "Epoch 271/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2459 - val_loss: 0.2620\n",
      "Epoch 272/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2454 - val_loss: 0.2635\n",
      "Epoch 273/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2451 - val_loss: 0.2604\n",
      "Epoch 274/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2449 - val_loss: 0.2638\n",
      "Epoch 275/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2443 - val_loss: 0.2631\n",
      "Epoch 276/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2438 - val_loss: 0.2625\n",
      "Epoch 277/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2439 - val_loss: 0.2614\n",
      "Epoch 278/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2437 - val_loss: 0.2600\n",
      "Epoch 279/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2437 - val_loss: 0.2611\n",
      "Epoch 280/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2428 - val_loss: 0.2608\n",
      "Epoch 281/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2431 - val_loss: 0.2610\n",
      "Epoch 282/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2431 - val_loss: 0.2622\n",
      "Epoch 283/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2421 - val_loss: 0.2597\n",
      "Epoch 284/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2424 - val_loss: 0.2618\n",
      "Epoch 285/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2419 - val_loss: 0.2592\n",
      "Epoch 286/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2412 - val_loss: 0.2601\n",
      "Epoch 287/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2418 - val_loss: 0.2578\n",
      "Epoch 288/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2412 - val_loss: 0.2622\n",
      "Epoch 289/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2409 - val_loss: 0.2577\n",
      "Epoch 290/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2413 - val_loss: 0.2608\n",
      "Epoch 291/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2416 - val_loss: 0.2619\n",
      "Epoch 292/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2428 - val_loss: 0.2552\n",
      "Epoch 293/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2412 - val_loss: 0.2608\n",
      "Epoch 294/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2405 - val_loss: 0.2599\n",
      "Epoch 295/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2403 - val_loss: 0.2556\n",
      "Epoch 296/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2388 - val_loss: 0.2590\n",
      "Epoch 297/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2392 - val_loss: 0.2587\n",
      "Epoch 298/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2389 - val_loss: 0.2579\n",
      "Epoch 299/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2386 - val_loss: 0.2595\n",
      "Epoch 300/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2390 - val_loss: 0.2540\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2382 - val_loss: 0.2635\n",
      "Epoch 302/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.270 - 0s 40us/sample - loss: 0.2378 - val_loss: 0.2549\n",
      "Epoch 303/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2375 - val_loss: 0.2552\n",
      "Epoch 304/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2377 - val_loss: 0.2588\n",
      "Epoch 305/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2372 - val_loss: 0.2536\n",
      "Epoch 306/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2369 - val_loss: 0.2580\n",
      "Epoch 307/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2361 - val_loss: 0.2552\n",
      "Epoch 308/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2370 - val_loss: 0.2587\n",
      "Epoch 309/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2364 - val_loss: 0.2558\n",
      "Epoch 310/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2360 - val_loss: 0.2523\n",
      "Epoch 311/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2355 - val_loss: 0.2557\n",
      "Epoch 312/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2359 - val_loss: 0.2531\n",
      "Epoch 313/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2357 - val_loss: 0.2582\n",
      "Epoch 314/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2353 - val_loss: 0.2538\n",
      "Epoch 315/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2341 - val_loss: 0.2526\n",
      "Epoch 316/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2342 - val_loss: 0.2529\n",
      "Epoch 317/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2340 - val_loss: 0.2543\n",
      "Epoch 318/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2341 - val_loss: 0.2520\n",
      "Epoch 319/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2343 - val_loss: 0.2553\n",
      "Epoch 320/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2334 - val_loss: 0.2507\n",
      "Epoch 321/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2361 - val_loss: 0.2566\n",
      "Epoch 322/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2335 - val_loss: 0.2541\n",
      "Epoch 323/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2326 - val_loss: 0.2514\n",
      "Epoch 324/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2340 - val_loss: 0.2498\n",
      "Epoch 325/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2329 - val_loss: 0.2627\n",
      "Epoch 326/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2344 - val_loss: 0.2489\n",
      "Epoch 327/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2357 - val_loss: 0.2599\n",
      "Epoch 328/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2328 - val_loss: 0.2500\n",
      "Epoch 329/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2309 - val_loss: 0.2536\n",
      "Epoch 330/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2310 - val_loss: 0.2494\n",
      "Epoch 331/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2317 - val_loss: 0.2550\n",
      "Epoch 332/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2304 - val_loss: 0.2503\n",
      "Epoch 333/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2308 - val_loss: 0.2496\n",
      "Epoch 334/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2312 - val_loss: 0.2517\n",
      "Epoch 335/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2326 - val_loss: 0.2582\n",
      "Epoch 336/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2311 - val_loss: 0.2478\n",
      "Epoch 337/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2301 - val_loss: 0.2509\n",
      "Epoch 338/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2291 - val_loss: 0.2502\n",
      "Epoch 339/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2290 - val_loss: 0.2484\n",
      "Epoch 340/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2284 - val_loss: 0.2501\n",
      "Epoch 341/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2285 - val_loss: 0.2478\n",
      "Epoch 342/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2289 - val_loss: 0.2503\n",
      "Epoch 343/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2283 - val_loss: 0.2513\n",
      "Epoch 344/1000\n",
      "1791/1791 [==============================] - 0s 46us/sample - loss: 0.2278 - val_loss: 0.2480\n",
      "Epoch 345/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2280 - val_loss: 0.2481\n",
      "Epoch 346/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2283 - val_loss: 0.2491\n",
      "Epoch 347/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2277 - val_loss: 0.2502\n",
      "Epoch 348/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2284 - val_loss: 0.2464\n",
      "Epoch 349/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2273 - val_loss: 0.2504\n",
      "Epoch 350/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2279 - val_loss: 0.2470\n",
      "Epoch 351/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2268 - val_loss: 0.2470\n",
      "Epoch 352/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2275 - val_loss: 0.2457\n",
      "Epoch 353/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2261 - val_loss: 0.2488\n",
      "Epoch 354/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2261 - val_loss: 0.2447\n",
      "Epoch 355/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2256 - val_loss: 0.2544\n",
      "Epoch 356/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2288 - val_loss: 0.2491\n",
      "Epoch 357/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2260 - val_loss: 0.2460\n",
      "Epoch 358/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2251 - val_loss: 0.2488\n",
      "Epoch 359/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2249 - val_loss: 0.2454\n",
      "Epoch 360/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2245 - val_loss: 0.2473\n",
      "Epoch 361/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2243 - val_loss: 0.2462\n",
      "Epoch 362/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2242 - val_loss: 0.2456\n",
      "Epoch 363/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2243 - val_loss: 0.2461\n",
      "Epoch 364/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2238 - val_loss: 0.2460\n",
      "Epoch 365/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2236 - val_loss: 0.2472\n",
      "Epoch 366/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2239 - val_loss: 0.2461\n",
      "Epoch 367/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2234 - val_loss: 0.2470\n",
      "Epoch 368/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2242 - val_loss: 0.2476\n",
      "Epoch 369/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2231 - val_loss: 0.2433\n",
      "Epoch 370/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2244 - val_loss: 0.2452\n",
      "Epoch 371/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2228 - val_loss: 0.2456\n",
      "Epoch 372/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2228 - val_loss: 0.2425\n",
      "Epoch 373/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2233 - val_loss: 0.2491\n",
      "Epoch 374/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2243 - val_loss: 0.2487\n",
      "Epoch 375/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2224 - val_loss: 0.2421\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2248 - val_loss: 0.2520\n",
      "Epoch 377/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2231 - val_loss: 0.2439\n",
      "Epoch 378/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2233 - val_loss: 0.2427\n",
      "Epoch 379/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2208 - val_loss: 0.2453\n",
      "Epoch 380/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2215 - val_loss: 0.2442\n",
      "Epoch 381/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2210 - val_loss: 0.2464\n",
      "Epoch 382/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2206 - val_loss: 0.2421\n",
      "Epoch 383/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2214 - val_loss: 0.2508\n",
      "Epoch 384/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2236 - val_loss: 0.2401\n",
      "Epoch 385/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2202 - val_loss: 0.2480\n",
      "Epoch 386/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2197 - val_loss: 0.2406\n",
      "Epoch 387/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2241 - val_loss: 0.2482\n",
      "Epoch 388/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2191 - val_loss: 0.2410\n",
      "Epoch 389/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2199 - val_loss: 0.2423\n",
      "Epoch 390/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2195 - val_loss: 0.2450\n",
      "Epoch 391/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.2200 - val_loss: 0.2421\n",
      "Epoch 392/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2231 - val_loss: 0.2403\n",
      "Epoch 393/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2242 - val_loss: 0.2488\n",
      "Epoch 394/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2206 - val_loss: 0.2417\n",
      "Epoch 395/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2190 - val_loss: 0.2408\n",
      "Epoch 396/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2185 - val_loss: 0.2441\n",
      "Epoch 397/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2184 - val_loss: 0.2441\n",
      "Epoch 398/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2178 - val_loss: 0.2427\n",
      "Epoch 399/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2180 - val_loss: 0.2395\n",
      "Epoch 400/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2178 - val_loss: 0.2415\n",
      "Epoch 401/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2175 - val_loss: 0.2431\n",
      "Epoch 402/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2178 - val_loss: 0.2427\n",
      "Epoch 403/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.2174 - val_loss: 0.2391\n",
      "Epoch 404/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2180 - val_loss: 0.2419\n",
      "Epoch 405/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2174 - val_loss: 0.2456\n",
      "Epoch 406/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2181 - val_loss: 0.2387\n",
      "Epoch 407/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2163 - val_loss: 0.2414\n",
      "Epoch 408/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2170 - val_loss: 0.2474\n",
      "Epoch 409/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2164 - val_loss: 0.2375\n",
      "Epoch 410/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2164 - val_loss: 0.2414\n",
      "Epoch 411/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2161 - val_loss: 0.2441\n",
      "Epoch 412/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2158 - val_loss: 0.2383\n",
      "Epoch 413/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2181 - val_loss: 0.2455\n",
      "Epoch 414/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2169 - val_loss: 0.2416\n",
      "Epoch 415/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2153 - val_loss: 0.2411\n",
      "Epoch 416/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2159 - val_loss: 0.2418\n",
      "Epoch 417/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2144 - val_loss: 0.2387\n",
      "Epoch 418/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2173 - val_loss: 0.2479\n",
      "Epoch 419/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2149 - val_loss: 0.2378\n",
      "Epoch 420/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.2145 - val_loss: 0.2385\n",
      "Epoch 421/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2141 - val_loss: 0.2425\n",
      "Epoch 422/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.2150 - val_loss: 0.2362\n",
      "Epoch 423/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.2146 - val_loss: 0.2390\n",
      "Epoch 424/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.2139 - val_loss: 0.2365\n",
      "Epoch 425/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2132 - val_loss: 0.2422\n",
      "Epoch 426/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2140 - val_loss: 0.2367\n",
      "Epoch 427/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2132 - val_loss: 0.2387\n",
      "Epoch 428/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2128 - val_loss: 0.2379\n",
      "Epoch 429/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2134 - val_loss: 0.2441\n",
      "Epoch 430/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2141 - val_loss: 0.2380\n",
      "Epoch 431/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2128 - val_loss: 0.2386\n",
      "Epoch 432/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2123 - val_loss: 0.2429\n",
      "Epoch 433/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2137 - val_loss: 0.2405\n",
      "Epoch 434/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.2122 - val_loss: 0.2399\n",
      "Epoch 435/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2119 - val_loss: 0.2391\n",
      "Epoch 436/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2129 - val_loss: 0.2362\n",
      "Epoch 437/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2124 - val_loss: 0.2343\n",
      "Epoch 438/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2121 - val_loss: 0.2401\n",
      "Epoch 439/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2127 - val_loss: 0.2404\n",
      "Epoch 440/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.2131 - val_loss: 0.2348\n",
      "Epoch 441/1000\n",
      "1791/1791 [==============================] - 0s 45us/sample - loss: 0.2115 - val_loss: 0.2344\n",
      "Epoch 442/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2102 - val_loss: 0.2422\n",
      "Epoch 443/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2121 - val_loss: 0.2335\n",
      "Epoch 444/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2111 - val_loss: 0.2392\n",
      "Epoch 445/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2100 - val_loss: 0.2332\n",
      "Epoch 446/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2127 - val_loss: 0.2332\n",
      "Epoch 447/1000\n",
      "1791/1791 [==============================] - 0s 46us/sample - loss: 0.2123 - val_loss: 0.2430\n",
      "Epoch 448/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2102 - val_loss: 0.2359\n",
      "Epoch 449/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2094 - val_loss: 0.2365\n",
      "Epoch 450/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2089 - val_loss: 0.2341\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2093 - val_loss: 0.2342\n",
      "Epoch 452/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2086 - val_loss: 0.2367\n",
      "Epoch 453/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2089 - val_loss: 0.2356\n",
      "Epoch 454/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2090 - val_loss: 0.2381\n",
      "Epoch 455/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.2088 - val_loss: 0.2319\n",
      "Epoch 456/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2106 - val_loss: 0.2395\n",
      "Epoch 457/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2115 - val_loss: 0.2423\n",
      "Epoch 458/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2114 - val_loss: 0.2327\n",
      "Epoch 459/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2075 - val_loss: 0.2362\n",
      "Epoch 460/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2079 - val_loss: 0.2352\n",
      "Epoch 461/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2074 - val_loss: 0.2329\n",
      "Epoch 462/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2073 - val_loss: 0.2325\n",
      "Epoch 463/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2075 - val_loss: 0.2408\n",
      "Epoch 464/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.2091 - val_loss: 0.2316\n",
      "Epoch 465/1000\n",
      "1791/1791 [==============================] - 0s 44us/sample - loss: 0.2065 - val_loss: 0.2377\n",
      "Epoch 466/1000\n",
      "1791/1791 [==============================] - 0s 41us/sample - loss: 0.2064 - val_loss: 0.2318\n",
      "Epoch 467/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2064 - val_loss: 0.2327\n",
      "Epoch 468/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2075 - val_loss: 0.2363\n",
      "Epoch 469/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2068 - val_loss: 0.2335\n",
      "Epoch 470/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2069 - val_loss: 0.2364\n",
      "Epoch 471/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2062 - val_loss: 0.2305\n",
      "Epoch 472/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2058 - val_loss: 0.2332\n",
      "Epoch 473/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2051 - val_loss: 0.2313\n",
      "Epoch 474/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2052 - val_loss: 0.2290\n",
      "Epoch 475/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.2047 - val_loss: 0.2350\n",
      "Epoch 476/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.2058 - val_loss: 0.2285\n",
      "Epoch 477/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2060 - val_loss: 0.2411\n",
      "Epoch 478/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.2050 - val_loss: 0.2276\n",
      "Epoch 479/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2060 - val_loss: 0.2305\n",
      "Epoch 480/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.2041 - val_loss: 0.2299\n",
      "Epoch 481/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2050 - val_loss: 0.2292\n",
      "Epoch 482/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2040 - val_loss: 0.2291\n",
      "Epoch 483/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2035 - val_loss: 0.2300\n",
      "Epoch 484/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2038 - val_loss: 0.2284\n",
      "Epoch 485/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.2040 - val_loss: 0.2277\n",
      "Epoch 486/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2041 - val_loss: 0.2292\n",
      "Epoch 487/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2036 - val_loss: 0.2343\n",
      "Epoch 488/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2051 - val_loss: 0.2274\n",
      "Epoch 489/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2041 - val_loss: 0.2307\n",
      "Epoch 490/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2029 - val_loss: 0.2256\n",
      "Epoch 491/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.2038 - val_loss: 0.2345\n",
      "Epoch 492/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2029 - val_loss: 0.2278\n",
      "Epoch 493/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2026 - val_loss: 0.2270\n",
      "Epoch 494/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2022 - val_loss: 0.2264\n",
      "Epoch 495/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2022 - val_loss: 0.2280\n",
      "Epoch 496/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2020 - val_loss: 0.2288\n",
      "Epoch 497/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2017 - val_loss: 0.2261\n",
      "Epoch 498/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.2017 - val_loss: 0.2263\n",
      "Epoch 499/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2010 - val_loss: 0.2284\n",
      "Epoch 500/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2024 - val_loss: 0.2241\n",
      "Epoch 501/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2019 - val_loss: 0.2307\n",
      "Epoch 502/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2005 - val_loss: 0.2247\n",
      "Epoch 503/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.2008 - val_loss: 0.2333\n",
      "Epoch 504/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.2018 - val_loss: 0.2237\n",
      "Epoch 505/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.2015 - val_loss: 0.2284\n",
      "Epoch 506/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2021 - val_loss: 0.2349\n",
      "Epoch 507/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2024 - val_loss: 0.2235\n",
      "Epoch 508/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2002 - val_loss: 0.2270\n",
      "Epoch 509/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2021 - val_loss: 0.2228\n",
      "Epoch 510/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.2018 - val_loss: 0.2253\n",
      "Epoch 511/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2000 - val_loss: 0.2263\n",
      "Epoch 512/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1998 - val_loss: 0.2264\n",
      "Epoch 513/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2007 - val_loss: 0.2302\n",
      "Epoch 514/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.2002 - val_loss: 0.2236\n",
      "Epoch 515/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1995 - val_loss: 0.2288\n",
      "Epoch 516/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.2005 - val_loss: 0.2271\n",
      "Epoch 517/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2016 - val_loss: 0.2286\n",
      "Epoch 518/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.2007 - val_loss: 0.2227\n",
      "Epoch 519/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1994 - val_loss: 0.2259\n",
      "Epoch 520/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2011 - val_loss: 0.2337\n",
      "Epoch 521/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.2049 - val_loss: 0.2206\n",
      "Epoch 522/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1993 - val_loss: 0.2234\n",
      "Epoch 523/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1991 - val_loss: 0.2229\n",
      "Epoch 524/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1987 - val_loss: 0.2216\n",
      "Epoch 525/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1991 - val_loss: 0.2218\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1982 - val_loss: 0.2221\n",
      "Epoch 527/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1977 - val_loss: 0.2257\n",
      "Epoch 528/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1985 - val_loss: 0.2223\n",
      "Epoch 529/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1977 - val_loss: 0.2216\n",
      "Epoch 530/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.2020 - val_loss: 0.2321\n",
      "Epoch 531/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1991 - val_loss: 0.2230\n",
      "Epoch 532/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1985 - val_loss: 0.2195\n",
      "Epoch 533/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1981 - val_loss: 0.2242\n",
      "Epoch 534/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1975 - val_loss: 0.2197\n",
      "Epoch 535/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.1975 - val_loss: 0.2214\n",
      "Epoch 536/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1968 - val_loss: 0.2236\n",
      "Epoch 537/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1972 - val_loss: 0.2228\n",
      "Epoch 538/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1981 - val_loss: 0.2209\n",
      "Epoch 539/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1968 - val_loss: 0.2216\n",
      "Epoch 540/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1964 - val_loss: 0.2233\n",
      "Epoch 541/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1971 - val_loss: 0.2224\n",
      "Epoch 542/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1967 - val_loss: 0.2189\n",
      "Epoch 543/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1993 - val_loss: 0.2233\n",
      "Epoch 544/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.2002 - val_loss: 0.2248\n",
      "Epoch 545/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1965 - val_loss: 0.2212\n",
      "Epoch 546/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1960 - val_loss: 0.2225\n",
      "Epoch 547/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1963 - val_loss: 0.2240\n",
      "Epoch 548/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1959 - val_loss: 0.2189\n",
      "Epoch 549/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1964 - val_loss: 0.2322\n",
      "Epoch 550/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1988 - val_loss: 0.2212\n",
      "Epoch 551/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1993 - val_loss: 0.2175\n",
      "Epoch 552/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1955 - val_loss: 0.2214\n",
      "Epoch 553/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1955 - val_loss: 0.2231\n",
      "Epoch 554/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1961 - val_loss: 0.2195\n",
      "Epoch 555/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.1951 - val_loss: 0.2189\n",
      "Epoch 556/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1955 - val_loss: 0.2198\n",
      "Epoch 557/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1948 - val_loss: 0.2207\n",
      "Epoch 558/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1943 - val_loss: 0.2186\n",
      "Epoch 559/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1951 - val_loss: 0.2188\n",
      "Epoch 560/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1956 - val_loss: 0.2203\n",
      "Epoch 561/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1964 - val_loss: 0.2218\n",
      "Epoch 562/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1940 - val_loss: 0.2173\n",
      "Epoch 563/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1939 - val_loss: 0.2197\n",
      "Epoch 564/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1940 - val_loss: 0.2189\n",
      "Epoch 565/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1967 - val_loss: 0.2226\n",
      "Epoch 566/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1943 - val_loss: 0.2189\n",
      "Epoch 567/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1937 - val_loss: 0.2162\n",
      "Epoch 568/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1938 - val_loss: 0.2218\n",
      "Epoch 569/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1939 - val_loss: 0.2163\n",
      "Epoch 570/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1954 - val_loss: 0.2247\n",
      "Epoch 571/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1971 - val_loss: 0.2217\n",
      "Epoch 572/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1961 - val_loss: 0.2158\n",
      "Epoch 573/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1932 - val_loss: 0.2207\n",
      "Epoch 574/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1931 - val_loss: 0.2151\n",
      "Epoch 575/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1934 - val_loss: 0.2207\n",
      "Epoch 576/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1932 - val_loss: 0.2149\n",
      "Epoch 577/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1941 - val_loss: 0.2149\n",
      "Epoch 578/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1947 - val_loss: 0.2162\n",
      "Epoch 579/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1943 - val_loss: 0.2150\n",
      "Epoch 580/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1953 - val_loss: 0.2208\n",
      "Epoch 581/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1938 - val_loss: 0.2208\n",
      "Epoch 582/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1931 - val_loss: 0.2142\n",
      "Epoch 583/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1935 - val_loss: 0.2140\n",
      "Epoch 584/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1918 - val_loss: 0.2228\n",
      "Epoch 585/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1942 - val_loss: 0.2164\n",
      "Epoch 586/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1915 - val_loss: 0.2188\n",
      "Epoch 587/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1942 - val_loss: 0.2149\n",
      "Epoch 588/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1921 - val_loss: 0.2158\n",
      "Epoch 589/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1956 - val_loss: 0.2212\n",
      "Epoch 590/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1923 - val_loss: 0.2169\n",
      "Epoch 591/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1915 - val_loss: 0.2137\n",
      "Epoch 592/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1921 - val_loss: 0.2176\n",
      "Epoch 593/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1909 - val_loss: 0.2140\n",
      "Epoch 594/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1910 - val_loss: 0.2166\n",
      "Epoch 595/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1915 - val_loss: 0.2148\n",
      "Epoch 596/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1908 - val_loss: 0.2151\n",
      "Epoch 597/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1907 - val_loss: 0.2155\n",
      "Epoch 598/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1920 - val_loss: 0.2136\n",
      "Epoch 599/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1918 - val_loss: 0.2124\n",
      "Epoch 600/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1912 - val_loss: 0.2211\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1944 - val_loss: 0.2128\n",
      "Epoch 602/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1943 - val_loss: 0.2115\n",
      "Epoch 603/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1955 - val_loss: 0.2183\n",
      "Epoch 604/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1930 - val_loss: 0.2232\n",
      "Epoch 605/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1956 - val_loss: 0.2113\n",
      "Epoch 606/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1943 - val_loss: 0.2119\n",
      "Epoch 607/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1938 - val_loss: 0.2242\n",
      "Epoch 608/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1928 - val_loss: 0.2134\n",
      "Epoch 609/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1909 - val_loss: 0.2114\n",
      "Epoch 610/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1906 - val_loss: 0.2131\n",
      "Epoch 611/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1896 - val_loss: 0.2138\n",
      "Epoch 612/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1897 - val_loss: 0.2129\n",
      "Epoch 613/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1901 - val_loss: 0.2124\n",
      "Epoch 614/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1899 - val_loss: 0.2114\n",
      "Epoch 615/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1902 - val_loss: 0.2124\n",
      "Epoch 616/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1896 - val_loss: 0.2146\n",
      "Epoch 617/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1894 - val_loss: 0.2134\n",
      "Epoch 618/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1894 - val_loss: 0.2114\n",
      "Epoch 619/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1886 - val_loss: 0.2183\n",
      "Epoch 620/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1910 - val_loss: 0.2095\n",
      "Epoch 621/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1901 - val_loss: 0.2128\n",
      "Epoch 622/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1898 - val_loss: 0.2130\n",
      "Epoch 623/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1885 - val_loss: 0.2111\n",
      "Epoch 624/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1888 - val_loss: 0.2102\n",
      "Epoch 625/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1886 - val_loss: 0.2118\n",
      "Epoch 626/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1892 - val_loss: 0.2090\n",
      "Epoch 627/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1894 - val_loss: 0.2141\n",
      "Epoch 628/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1887 - val_loss: 0.2135\n",
      "Epoch 629/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1890 - val_loss: 0.2115\n",
      "Epoch 630/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1886 - val_loss: 0.2094\n",
      "Epoch 631/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1885 - val_loss: 0.2129\n",
      "Epoch 632/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1914 - val_loss: 0.2218\n",
      "Epoch 633/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1890 - val_loss: 0.2086\n",
      "Epoch 634/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1887 - val_loss: 0.2138\n",
      "Epoch 635/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1876 - val_loss: 0.2081\n",
      "Epoch 636/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1889 - val_loss: 0.2118\n",
      "Epoch 637/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1878 - val_loss: 0.2115\n",
      "Epoch 638/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1886 - val_loss: 0.2080\n",
      "Epoch 639/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1887 - val_loss: 0.2190\n",
      "Epoch 640/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1902 - val_loss: 0.2144\n",
      "Epoch 641/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1889 - val_loss: 0.2078\n",
      "Epoch 642/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1893 - val_loss: 0.2113\n",
      "Epoch 643/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1869 - val_loss: 0.2094\n",
      "Epoch 644/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1876 - val_loss: 0.2152\n",
      "Epoch 645/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1873 - val_loss: 0.2075\n",
      "Epoch 646/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1871 - val_loss: 0.2099\n",
      "Epoch 647/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1870 - val_loss: 0.2099\n",
      "Epoch 648/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1895 - val_loss: 0.2071\n",
      "Epoch 649/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1869 - val_loss: 0.2094\n",
      "Epoch 650/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1870 - val_loss: 0.2104\n",
      "Epoch 651/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1867 - val_loss: 0.2069\n",
      "Epoch 652/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1906 - val_loss: 0.2232\n",
      "Epoch 653/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1888 - val_loss: 0.2072\n",
      "Epoch 654/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1868 - val_loss: 0.2079\n",
      "Epoch 655/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.1861 - val_loss: 0.2108\n",
      "Epoch 656/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1859 - val_loss: 0.2064\n",
      "Epoch 657/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1870 - val_loss: 0.2125\n",
      "Epoch 658/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1867 - val_loss: 0.2098\n",
      "Epoch 659/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1863 - val_loss: 0.2057\n",
      "Epoch 660/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1904 - val_loss: 0.2133\n",
      "Epoch 661/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1872 - val_loss: 0.2071\n",
      "Epoch 662/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1865 - val_loss: 0.2119\n",
      "Epoch 663/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1860 - val_loss: 0.2082\n",
      "Epoch 664/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1855 - val_loss: 0.2072\n",
      "Epoch 665/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1857 - val_loss: 0.2083\n",
      "Epoch 666/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1851 - val_loss: 0.2067\n",
      "Epoch 667/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1852 - val_loss: 0.2107\n",
      "Epoch 668/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1856 - val_loss: 0.2059\n",
      "Epoch 669/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1846 - val_loss: 0.2137\n",
      "Epoch 670/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1854 - val_loss: 0.2052\n",
      "Epoch 671/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1845 - val_loss: 0.2164\n",
      "Epoch 672/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1869 - val_loss: 0.2048\n",
      "Epoch 673/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1835 - val_loss: 0.2136\n",
      "Epoch 674/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1875 - val_loss: 0.2112\n",
      "Epoch 675/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1864 - val_loss: 0.2049\n",
      "Epoch 676/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1866 - val_loss: 0.2042\n",
      "Epoch 677/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1846 - val_loss: 0.2131\n",
      "Epoch 678/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1862 - val_loss: 0.2074\n",
      "Epoch 679/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1842 - val_loss: 0.2053\n",
      "Epoch 680/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1840 - val_loss: 0.2064\n",
      "Epoch 681/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1839 - val_loss: 0.2049\n",
      "Epoch 682/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1846 - val_loss: 0.2065\n",
      "Epoch 683/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1852 - val_loss: 0.2102\n",
      "Epoch 684/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1841 - val_loss: 0.2043\n",
      "Epoch 685/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1839 - val_loss: 0.2063\n",
      "Epoch 686/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1833 - val_loss: 0.2053\n",
      "Epoch 687/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1834 - val_loss: 0.2082\n",
      "Epoch 688/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1834 - val_loss: 0.2054\n",
      "Epoch 689/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1840 - val_loss: 0.2088\n",
      "Epoch 690/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1851 - val_loss: 0.2114\n",
      "Epoch 691/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1855 - val_loss: 0.2031\n",
      "Epoch 692/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1840 - val_loss: 0.2047\n",
      "Epoch 693/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1844 - val_loss: 0.2100\n",
      "Epoch 694/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1842 - val_loss: 0.2070\n",
      "Epoch 695/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1856 - val_loss: 0.2026\n",
      "Epoch 696/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1823 - val_loss: 0.2076\n",
      "Epoch 697/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1834 - val_loss: 0.2078\n",
      "Epoch 698/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1841 - val_loss: 0.2039\n",
      "Epoch 699/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1836 - val_loss: 0.2027\n",
      "Epoch 700/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1829 - val_loss: 0.2072\n",
      "Epoch 701/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1825 - val_loss: 0.2045\n",
      "Epoch 702/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1836 - val_loss: 0.2039\n",
      "Epoch 703/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1824 - val_loss: 0.2027\n",
      "Epoch 704/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1821 - val_loss: 0.2041\n",
      "Epoch 705/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1822 - val_loss: 0.2033\n",
      "Epoch 706/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1819 - val_loss: 0.2087\n",
      "Epoch 707/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1847 - val_loss: 0.2023\n",
      "Epoch 708/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1824 - val_loss: 0.2096\n",
      "Epoch 709/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1827 - val_loss: 0.2043\n",
      "Epoch 710/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1821 - val_loss: 0.2027\n",
      "Epoch 711/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1816 - val_loss: 0.2066\n",
      "Epoch 712/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1826 - val_loss: 0.2055\n",
      "Epoch 713/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1822 - val_loss: 0.2020\n",
      "Epoch 714/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1853 - val_loss: 0.2015\n",
      "Epoch 715/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1841 - val_loss: 0.2017\n",
      "Epoch 716/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1827 - val_loss: 0.2114\n",
      "Epoch 717/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1826 - val_loss: 0.2021\n",
      "Epoch 718/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1814 - val_loss: 0.2112\n",
      "Epoch 719/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1833 - val_loss: 0.2011\n",
      "Epoch 720/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1798 - val_loss: 0.2099\n",
      "Epoch 721/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1807 - val_loss: 0.2010\n",
      "Epoch 722/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1844 - val_loss: 0.2101\n",
      "Epoch 723/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1818 - val_loss: 0.2019\n",
      "Epoch 724/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1814 - val_loss: 0.2000\n",
      "Epoch 725/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1805 - val_loss: 0.2027\n",
      "Epoch 726/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1805 - val_loss: 0.2010\n",
      "Epoch 727/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1805 - val_loss: 0.2009\n",
      "Epoch 728/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1816 - val_loss: 0.2085\n",
      "Epoch 729/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1803 - val_loss: 0.2006\n",
      "Epoch 730/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1811 - val_loss: 0.2044\n",
      "Epoch 731/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1794 - val_loss: 0.2000\n",
      "Epoch 732/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1799 - val_loss: 0.2008\n",
      "Epoch 733/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.124 - 0s 31us/sample - loss: 0.1809 - val_loss: 0.1998\n",
      "Epoch 734/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1822 - val_loss: 0.2018\n",
      "Epoch 735/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.1864 - val_loss: 0.2094\n",
      "Epoch 736/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1807 - val_loss: 0.2011\n",
      "Epoch 737/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1798 - val_loss: 0.2010\n",
      "Epoch 738/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1814 - val_loss: 0.1995\n",
      "Epoch 739/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1803 - val_loss: 0.2009\n",
      "Epoch 740/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1802 - val_loss: 0.2057\n",
      "Epoch 741/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1828 - val_loss: 0.2000\n",
      "Epoch 742/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1800 - val_loss: 0.1997\n",
      "Epoch 743/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1800 - val_loss: 0.2060\n",
      "Epoch 744/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1787 - val_loss: 0.1981\n",
      "Epoch 745/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1813 - val_loss: 0.2054\n",
      "Epoch 746/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1805 - val_loss: 0.2037\n",
      "Epoch 747/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1809 - val_loss: 0.1978\n",
      "Epoch 748/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1853 - val_loss: 0.1990\n",
      "Epoch 749/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1821 - val_loss: 0.2074\n",
      "Epoch 750/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1793 - val_loss: 0.1996\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1788 - val_loss: 0.1985\n",
      "Epoch 752/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1794 - val_loss: 0.2046\n",
      "Epoch 753/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1812 - val_loss: 0.1980\n",
      "Epoch 754/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1797 - val_loss: 0.1995\n",
      "Epoch 755/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1791 - val_loss: 0.1985\n",
      "Epoch 756/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1823 - val_loss: 0.2130\n",
      "Epoch 757/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.1819 - val_loss: 0.1981\n",
      "Epoch 758/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1808 - val_loss: 0.1971\n",
      "Epoch 759/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1817 - val_loss: 0.2107\n",
      "Epoch 760/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1785 - val_loss: 0.1971\n",
      "Epoch 761/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1780 - val_loss: 0.2007\n",
      "Epoch 762/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1777 - val_loss: 0.1977\n",
      "Epoch 763/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1777 - val_loss: 0.1995\n",
      "Epoch 764/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1812 - val_loss: 0.2072\n",
      "Epoch 765/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1819 - val_loss: 0.2067\n",
      "Epoch 766/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1823 - val_loss: 0.1970\n",
      "Epoch 767/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1807 - val_loss: 0.1971\n",
      "Epoch 768/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1779 - val_loss: 0.1996\n",
      "Epoch 769/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1772 - val_loss: 0.1973\n",
      "Epoch 770/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1786 - val_loss: 0.2024\n",
      "Epoch 771/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1772 - val_loss: 0.1965\n",
      "Epoch 772/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1784 - val_loss: 0.2049\n",
      "Epoch 773/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1777 - val_loss: 0.1968\n",
      "Epoch 774/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1795 - val_loss: 0.1954\n",
      "Epoch 775/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1786 - val_loss: 0.1996\n",
      "Epoch 776/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1773 - val_loss: 0.1969\n",
      "Epoch 777/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1773 - val_loss: 0.1965\n",
      "Epoch 778/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1780 - val_loss: 0.2006\n",
      "Epoch 779/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1772 - val_loss: 0.1961\n",
      "Epoch 780/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1779 - val_loss: 0.2024\n",
      "Epoch 781/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1778 - val_loss: 0.1983\n",
      "Epoch 782/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1771 - val_loss: 0.1958\n",
      "Epoch 783/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1775 - val_loss: 0.1998\n",
      "Epoch 784/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1780 - val_loss: 0.2000\n",
      "Epoch 785/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1769 - val_loss: 0.1979\n",
      "Epoch 786/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1762 - val_loss: 0.2005\n",
      "Epoch 787/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1790 - val_loss: 0.1969\n",
      "Epoch 788/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1780 - val_loss: 0.1949\n",
      "Epoch 789/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1778 - val_loss: 0.1977\n",
      "Epoch 790/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1763 - val_loss: 0.1974\n",
      "Epoch 791/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1785 - val_loss: 0.2064\n",
      "Epoch 792/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1768 - val_loss: 0.1950\n",
      "Epoch 793/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1797 - val_loss: 0.1946\n",
      "Epoch 794/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1810 - val_loss: 0.2023\n",
      "Epoch 795/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1765 - val_loss: 0.1968\n",
      "Epoch 796/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1764 - val_loss: 0.1991\n",
      "Epoch 797/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1762 - val_loss: 0.1954\n",
      "Epoch 798/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1760 - val_loss: 0.1945\n",
      "Epoch 799/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1762 - val_loss: 0.1954\n",
      "Epoch 800/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1757 - val_loss: 0.1986\n",
      "Epoch 801/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1804 - val_loss: 0.2118\n",
      "Epoch 802/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1816 - val_loss: 0.1939\n",
      "Epoch 803/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1794 - val_loss: 0.1937\n",
      "Epoch 804/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1754 - val_loss: 0.1991\n",
      "Epoch 805/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1753 - val_loss: 0.1948\n",
      "Epoch 806/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1752 - val_loss: 0.1954\n",
      "Epoch 807/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1749 - val_loss: 0.1974\n",
      "Epoch 808/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1753 - val_loss: 0.1936\n",
      "Epoch 809/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1753 - val_loss: 0.1987\n",
      "Epoch 810/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1792 - val_loss: 0.1931\n",
      "Epoch 811/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1766 - val_loss: 0.1944\n",
      "Epoch 812/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1751 - val_loss: 0.1941\n",
      "Epoch 813/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1751 - val_loss: 0.2001\n",
      "Epoch 814/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1765 - val_loss: 0.1925\n",
      "Epoch 815/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1762 - val_loss: 0.1952\n",
      "Epoch 816/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1768 - val_loss: 0.1987\n",
      "Epoch 817/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1743 - val_loss: 0.1934\n",
      "Epoch 818/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1753 - val_loss: 0.1934\n",
      "Epoch 819/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1747 - val_loss: 0.1983\n",
      "Epoch 820/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1750 - val_loss: 0.1922\n",
      "Epoch 821/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1753 - val_loss: 0.1964\n",
      "Epoch 822/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1742 - val_loss: 0.1935\n",
      "Epoch 823/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1748 - val_loss: 0.1929\n",
      "Epoch 824/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1744 - val_loss: 0.1962\n",
      "Epoch 825/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1749 - val_loss: 0.1980\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.1759 - val_loss: 0.1920\n",
      "Epoch 827/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1750 - val_loss: 0.1991\n",
      "Epoch 828/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1747 - val_loss: 0.1958\n",
      "Epoch 829/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1741 - val_loss: 0.1928\n",
      "Epoch 830/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1737 - val_loss: 0.1944\n",
      "Epoch 831/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.1735 - val_loss: 0.1936\n",
      "Epoch 832/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1736 - val_loss: 0.1939\n",
      "Epoch 833/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1737 - val_loss: 0.1930\n",
      "Epoch 834/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1737 - val_loss: 0.1925\n",
      "Epoch 835/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.283 - 0s 35us/sample - loss: 0.1745 - val_loss: 0.1947\n",
      "Epoch 836/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1744 - val_loss: 0.1910\n",
      "Epoch 837/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1737 - val_loss: 0.1960\n",
      "Epoch 838/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1741 - val_loss: 0.1926\n",
      "Epoch 839/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1734 - val_loss: 0.1979\n",
      "Epoch 840/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1759 - val_loss: 0.1960\n",
      "Epoch 841/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1736 - val_loss: 0.1918\n",
      "Epoch 842/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1740 - val_loss: 0.1924\n",
      "Epoch 843/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1745 - val_loss: 0.1945\n",
      "Epoch 844/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1744 - val_loss: 0.1982\n",
      "Epoch 845/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1743 - val_loss: 0.1915\n",
      "Epoch 846/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1737 - val_loss: 0.1915\n",
      "Epoch 847/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1730 - val_loss: 0.1951\n",
      "Epoch 848/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1731 - val_loss: 0.1913\n",
      "Epoch 849/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1731 - val_loss: 0.1925\n",
      "Epoch 850/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1730 - val_loss: 0.1914\n",
      "Epoch 851/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1735 - val_loss: 0.1931\n",
      "Epoch 852/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1740 - val_loss: 0.1930\n",
      "Epoch 853/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1734 - val_loss: 0.1910\n",
      "Epoch 854/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1724 - val_loss: 0.1946\n",
      "Epoch 855/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1729 - val_loss: 0.1918\n",
      "Epoch 856/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1738 - val_loss: 0.1906\n",
      "Epoch 857/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1724 - val_loss: 0.1967\n",
      "Epoch 858/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1742 - val_loss: 0.1903\n",
      "Epoch 859/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1730 - val_loss: 0.1908\n",
      "Epoch 860/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1730 - val_loss: 0.1905\n",
      "Epoch 861/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1731 - val_loss: 0.2001\n",
      "Epoch 862/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1738 - val_loss: 0.1900\n",
      "Epoch 863/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1728 - val_loss: 0.1955\n",
      "Epoch 864/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1721 - val_loss: 0.1905\n",
      "Epoch 865/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1734 - val_loss: 0.1900\n",
      "Epoch 866/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1723 - val_loss: 0.1908\n",
      "Epoch 867/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1723 - val_loss: 0.1912\n",
      "Epoch 868/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1724 - val_loss: 0.1900\n",
      "Epoch 869/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1737 - val_loss: 0.1905\n",
      "Epoch 870/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1733 - val_loss: 0.2013\n",
      "Epoch 871/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1749 - val_loss: 0.1908\n",
      "Epoch 872/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1726 - val_loss: 0.1899\n",
      "Epoch 873/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1736 - val_loss: 0.1887\n",
      "Epoch 874/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1727 - val_loss: 0.1937\n",
      "Epoch 875/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1723 - val_loss: 0.1895\n",
      "Epoch 876/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1716 - val_loss: 0.1924\n",
      "Epoch 877/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1719 - val_loss: 0.1919\n",
      "Epoch 878/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1715 - val_loss: 0.1884\n",
      "Epoch 879/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1731 - val_loss: 0.1920\n",
      "Epoch 880/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1730 - val_loss: 0.1982\n",
      "Epoch 881/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1745 - val_loss: 0.1888\n",
      "Epoch 882/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1715 - val_loss: 0.1907\n",
      "Epoch 883/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1716 - val_loss: 0.1914\n",
      "Epoch 884/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1712 - val_loss: 0.1891\n",
      "Epoch 885/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1712 - val_loss: 0.1939\n",
      "Epoch 886/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1729 - val_loss: 0.1908\n",
      "Epoch 887/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1747 - val_loss: 0.1879\n",
      "Epoch 888/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1735 - val_loss: 0.1949\n",
      "Epoch 889/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1736 - val_loss: 0.1996\n",
      "Epoch 890/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1735 - val_loss: 0.1884\n",
      "Epoch 891/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1747 - val_loss: 0.1911\n",
      "Epoch 892/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1718 - val_loss: 0.1925\n",
      "Epoch 893/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1707 - val_loss: 0.1886\n",
      "Epoch 894/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1710 - val_loss: 0.1917\n",
      "Epoch 895/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1711 - val_loss: 0.1877\n",
      "Epoch 896/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1715 - val_loss: 0.1949\n",
      "Epoch 897/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1718 - val_loss: 0.1877\n",
      "Epoch 898/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1724 - val_loss: 0.1896\n",
      "Epoch 899/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1720 - val_loss: 0.1908\n",
      "Epoch 900/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1729 - val_loss: 0.1876\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1727 - val_loss: 0.1905\n",
      "Epoch 902/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1705 - val_loss: 0.1898\n",
      "Epoch 903/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1718 - val_loss: 0.1868\n",
      "Epoch 904/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1740 - val_loss: 0.1884\n",
      "Epoch 905/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1746 - val_loss: 0.2034\n",
      "Epoch 906/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1733 - val_loss: 0.1868\n",
      "Epoch 907/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1737 - val_loss: 0.1871\n",
      "Epoch 908/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1735 - val_loss: 0.1893\n",
      "Epoch 909/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1711 - val_loss: 0.1936\n",
      "Epoch 910/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1726 - val_loss: 0.1864\n",
      "Epoch 911/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1724 - val_loss: 0.1871\n",
      "Epoch 912/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1712 - val_loss: 0.1943\n",
      "Epoch 913/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1708 - val_loss: 0.1879\n",
      "Epoch 914/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1703 - val_loss: 0.1945\n",
      "Epoch 915/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1697 - val_loss: 0.1864\n",
      "Epoch 916/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1695 - val_loss: 0.1938\n",
      "Epoch 917/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1718 - val_loss: 0.1853\n",
      "Epoch 918/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1704 - val_loss: 0.1875\n",
      "Epoch 919/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1700 - val_loss: 0.1912\n",
      "Epoch 920/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1712 - val_loss: 0.1916\n",
      "Epoch 921/1000\n",
      "1791/1791 [==============================] - 0s 24us/sample - loss: 0.1715 - val_loss: 0.1855\n",
      "Epoch 922/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1681 - val_loss: 0.1992\n",
      "Epoch 923/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1723 - val_loss: 0.1854\n",
      "Epoch 924/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1708 - val_loss: 0.1876\n",
      "Epoch 925/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1693 - val_loss: 0.1867\n",
      "Epoch 926/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1710 - val_loss: 0.1853\n",
      "Epoch 927/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1692 - val_loss: 0.1862\n",
      "Epoch 928/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1694 - val_loss: 0.1918\n",
      "Epoch 929/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1712 - val_loss: 0.1856\n",
      "Epoch 930/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1708 - val_loss: 0.1841\n",
      "Epoch 931/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1712 - val_loss: 0.1860\n",
      "Epoch 932/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1697 - val_loss: 0.1920\n",
      "Epoch 933/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1693 - val_loss: 0.1836\n",
      "Epoch 934/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1700 - val_loss: 0.1872\n",
      "Epoch 935/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1694 - val_loss: 0.1860\n",
      "Epoch 936/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1698 - val_loss: 0.1887\n",
      "Epoch 937/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1690 - val_loss: 0.1873\n",
      "Epoch 938/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.1710 - val_loss: 0.1839\n",
      "Epoch 939/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.1679 - val_loss: 0.1860\n",
      "Epoch 940/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1682 - val_loss: 0.1834\n",
      "Epoch 941/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1714 - val_loss: 0.1922\n",
      "Epoch 942/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1712 - val_loss: 0.1869\n",
      "Epoch 943/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1678 - val_loss: 0.1842\n",
      "Epoch 944/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1685 - val_loss: 0.1836\n",
      "Epoch 945/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1681 - val_loss: 0.1841\n",
      "Epoch 946/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1688 - val_loss: 0.1861\n",
      "Epoch 947/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1674 - val_loss: 0.1836\n",
      "Epoch 948/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1683 - val_loss: 0.1818\n",
      "Epoch 949/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1680 - val_loss: 0.1853\n",
      "Epoch 950/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1675 - val_loss: 0.1837\n",
      "Epoch 951/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1673 - val_loss: 0.1821\n",
      "Epoch 952/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1687 - val_loss: 0.1824\n",
      "Epoch 953/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1671 - val_loss: 0.1837\n",
      "Epoch 954/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1678 - val_loss: 0.1819\n",
      "Epoch 955/1000\n",
      "1791/1791 [==============================] - 0s 22us/sample - loss: 0.1694 - val_loss: 0.1808\n",
      "Epoch 956/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1667 - val_loss: 0.1866\n",
      "Epoch 957/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1720 - val_loss: 0.1797\n",
      "Epoch 958/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1706 - val_loss: 0.1801\n",
      "Epoch 959/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1696 - val_loss: 0.1832\n",
      "Epoch 960/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1674 - val_loss: 0.1824\n",
      "Epoch 961/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1664 - val_loss: 0.1794\n",
      "Epoch 962/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1677 - val_loss: 0.1783\n",
      "Epoch 963/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.1696 - val_loss: 0.1947\n",
      "Epoch 964/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1676 - val_loss: 0.1784\n",
      "Epoch 965/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1667 - val_loss: 0.1805\n",
      "Epoch 966/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1682 - val_loss: 0.1823\n",
      "Epoch 967/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1658 - val_loss: 0.1792\n",
      "Epoch 968/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1664 - val_loss: 0.1787\n",
      "Epoch 969/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1659 - val_loss: 0.1825\n",
      "Epoch 970/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1664 - val_loss: 0.1800\n",
      "Epoch 971/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1673 - val_loss: 0.1813\n",
      "Epoch 972/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1672 - val_loss: 0.1776\n",
      "Epoch 973/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1664 - val_loss: 0.1796\n",
      "Epoch 974/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1654 - val_loss: 0.1798\n",
      "Epoch 975/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1654 - val_loss: 0.1784\n",
      "Epoch 976/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1657 - val_loss: 0.1801\n",
      "Epoch 977/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.1650 - val_loss: 0.1780\n",
      "Epoch 978/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1652 - val_loss: 0.1772\n",
      "Epoch 979/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1650 - val_loss: 0.1782\n",
      "Epoch 980/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1655 - val_loss: 0.1847\n",
      "Epoch 981/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.1682 - val_loss: 0.1758\n",
      "Epoch 982/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1672 - val_loss: 0.1763\n",
      "Epoch 983/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1658 - val_loss: 0.1783\n",
      "Epoch 984/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1666 - val_loss: 0.1823\n",
      "Epoch 985/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.1648 - val_loss: 0.1760\n",
      "Epoch 986/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1646 - val_loss: 0.1765\n",
      "Epoch 987/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1646 - val_loss: 0.1829\n",
      "Epoch 988/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1679 - val_loss: 0.1744\n",
      "Epoch 989/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1679 - val_loss: 0.1743\n",
      "Epoch 990/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1660 - val_loss: 0.1761\n",
      "Epoch 991/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1636 - val_loss: 0.1764\n",
      "Epoch 992/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1635 - val_loss: 0.1768\n",
      "Epoch 993/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.1643 - val_loss: 0.1761\n",
      "Epoch 994/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.1631 - val_loss: 0.1747\n",
      "Epoch 995/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.1640 - val_loss: 0.1766\n",
      "Epoch 996/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1636 - val_loss: 0.1759\n",
      "Epoch 997/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.1637 - val_loss: 0.1740\n",
      "Epoch 998/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.1645 - val_loss: 0.1801\n",
      "Epoch 999/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.1645 - val_loss: 0.1744\n",
      "Epoch 1000/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.1638 - val_loss: 0.1799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17060856848>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=1000,validation_data=(X_test,y_test),batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.712748</td>\n",
       "      <td>0.700726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.688224</td>\n",
       "      <td>0.682106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.670312</td>\n",
       "      <td>0.668250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.657111</td>\n",
       "      <td>0.656975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.646888</td>\n",
       "      <td>0.645809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>0.163639</td>\n",
       "      <td>0.175898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>0.163686</td>\n",
       "      <td>0.174040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>0.164532</td>\n",
       "      <td>0.180119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>0.164506</td>\n",
       "      <td>0.174437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>0.163850</td>\n",
       "      <td>0.179901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss\n",
       "0    0.712748  0.700726\n",
       "1    0.688224  0.682106\n",
       "2    0.670312  0.668250\n",
       "3    0.657111  0.656975\n",
       "4    0.646888  0.645809\n",
       "..        ...       ...\n",
       "995  0.163639  0.175898\n",
       "996  0.163686  0.174040\n",
       "997  0.164532  0.180119\n",
       "998  0.164506  0.174437\n",
       "999  0.163850  0.179901\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1706195e048>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(9,activation='relu',input_shape=(9, )))\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1791 samples, validate on 597 samples\n",
      "Epoch 1/1000\n",
      "1791/1791 [==============================] - 1s 425us/sample - loss: 0.6931 - val_loss: 0.7024\n",
      "Epoch 2/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.6794 - val_loss: 0.6880\n",
      "Epoch 3/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.6678 - val_loss: 0.6753\n",
      "Epoch 4/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.6560 - val_loss: 0.6611\n",
      "Epoch 5/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.6430 - val_loss: 0.6457\n",
      "Epoch 6/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.6261 - val_loss: 0.6229\n",
      "Epoch 7/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.6067 - val_loss: 0.6006\n",
      "Epoch 8/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.5887 - val_loss: 0.5814\n",
      "Epoch 9/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.5728 - val_loss: 0.5646\n",
      "Epoch 10/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.5588 - val_loss: 0.5477\n",
      "Epoch 11/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.5444 - val_loss: 0.5321\n",
      "Epoch 12/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.5316 - val_loss: 0.5191\n",
      "Epoch 13/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.5206 - val_loss: 0.5072\n",
      "Epoch 14/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.5110 - val_loss: 0.4964\n",
      "Epoch 15/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.5019 - val_loss: 0.4863\n",
      "Epoch 16/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.4945 - val_loss: 0.4780\n",
      "Epoch 17/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4882 - val_loss: 0.4712\n",
      "Epoch 18/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4825 - val_loss: 0.4641\n",
      "Epoch 19/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4779 - val_loss: 0.4588\n",
      "Epoch 20/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4723 - val_loss: 0.4530\n",
      "Epoch 21/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4676 - val_loss: 0.4486\n",
      "Epoch 22/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4637 - val_loss: 0.4436\n",
      "Epoch 23/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4598 - val_loss: 0.4389\n",
      "Epoch 24/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4556 - val_loss: 0.4353\n",
      "Epoch 25/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4519 - val_loss: 0.4308\n",
      "Epoch 26/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4482 - val_loss: 0.4268\n",
      "Epoch 27/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4445 - val_loss: 0.4229\n",
      "Epoch 28/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.4407 - val_loss: 0.4201\n",
      "Epoch 29/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4372 - val_loss: 0.4156\n",
      "Epoch 30/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.4335 - val_loss: 0.4124\n",
      "Epoch 31/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.4300 - val_loss: 0.4086\n",
      "Epoch 32/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4269 - val_loss: 0.4052\n",
      "Epoch 33/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.4236 - val_loss: 0.4019\n",
      "Epoch 34/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.4197 - val_loss: 0.3985\n",
      "Epoch 35/1000\n",
      "1791/1791 [==============================] - ETA: 0s - loss: 0.379 - 0s 31us/sample - loss: 0.4162 - val_loss: 0.3955\n",
      "Epoch 36/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.4131 - val_loss: 0.3920\n",
      "Epoch 37/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4097 - val_loss: 0.3899\n",
      "Epoch 38/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.4061 - val_loss: 0.3854\n",
      "Epoch 39/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.4038 - val_loss: 0.3832\n",
      "Epoch 40/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.4016 - val_loss: 0.3800\n",
      "Epoch 41/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3993 - val_loss: 0.3776\n",
      "Epoch 42/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3944 - val_loss: 0.3755\n",
      "Epoch 43/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3930 - val_loss: 0.3719\n",
      "Epoch 44/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3892 - val_loss: 0.3707\n",
      "Epoch 45/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3861 - val_loss: 0.3665\n",
      "Epoch 46/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3838 - val_loss: 0.3653\n",
      "Epoch 47/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3812 - val_loss: 0.3615\n",
      "Epoch 48/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3787 - val_loss: 0.3608\n",
      "Epoch 49/1000\n",
      "1791/1791 [==============================] - 0s 40us/sample - loss: 0.3766 - val_loss: 0.3586\n",
      "Epoch 50/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3744 - val_loss: 0.3556\n",
      "Epoch 51/1000\n",
      "1791/1791 [==============================] - 0s 39us/sample - loss: 0.3726 - val_loss: 0.3536\n",
      "Epoch 52/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3707 - val_loss: 0.3524\n",
      "Epoch 53/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3695 - val_loss: 0.3508\n",
      "Epoch 54/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3677 - val_loss: 0.3484\n",
      "Epoch 55/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3660 - val_loss: 0.3472\n",
      "Epoch 56/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.3669 - val_loss: 0.3450\n",
      "Epoch 57/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.3646 - val_loss: 0.3462\n",
      "Epoch 58/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3620 - val_loss: 0.3431\n",
      "Epoch 59/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3604 - val_loss: 0.3421\n",
      "Epoch 60/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3586 - val_loss: 0.3403\n",
      "Epoch 61/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3573 - val_loss: 0.3394\n",
      "Epoch 62/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3563 - val_loss: 0.3397\n",
      "Epoch 63/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3555 - val_loss: 0.3370\n",
      "Epoch 64/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3554 - val_loss: 0.3380\n",
      "Epoch 65/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3541 - val_loss: 0.3364\n",
      "Epoch 66/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3530 - val_loss: 0.3348\n",
      "Epoch 67/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3523 - val_loss: 0.3341\n",
      "Epoch 68/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.3511 - val_loss: 0.3335\n",
      "Epoch 69/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3502 - val_loss: 0.3314\n",
      "Epoch 70/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3493 - val_loss: 0.3327\n",
      "Epoch 71/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3488 - val_loss: 0.3326\n",
      "Epoch 72/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3478 - val_loss: 0.3302\n",
      "Epoch 73/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3483 - val_loss: 0.3298\n",
      "Epoch 74/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3484 - val_loss: 0.3300\n",
      "Epoch 75/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3478 - val_loss: 0.3280\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3459 - val_loss: 0.3291\n",
      "Epoch 77/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3443 - val_loss: 0.3259\n",
      "Epoch 78/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3438 - val_loss: 0.3277\n",
      "Epoch 79/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3434 - val_loss: 0.3256\n",
      "Epoch 80/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3431 - val_loss: 0.3259\n",
      "Epoch 81/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3421 - val_loss: 0.3251\n",
      "Epoch 82/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.3425 - val_loss: 0.3232\n",
      "Epoch 83/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.3429 - val_loss: 0.3246\n",
      "Epoch 84/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3445 - val_loss: 0.3222\n",
      "Epoch 85/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3421 - val_loss: 0.3251\n",
      "Epoch 86/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3401 - val_loss: 0.3231\n",
      "Epoch 87/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3394 - val_loss: 0.3217\n",
      "Epoch 88/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3395 - val_loss: 0.3229\n",
      "Epoch 89/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3394 - val_loss: 0.3229\n",
      "Epoch 90/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3384 - val_loss: 0.3210\n",
      "Epoch 91/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3374 - val_loss: 0.3226\n",
      "Epoch 92/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3378 - val_loss: 0.3200\n",
      "Epoch 93/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3374 - val_loss: 0.3224\n",
      "Epoch 94/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3370 - val_loss: 0.3200\n",
      "Epoch 95/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3363 - val_loss: 0.3209\n",
      "Epoch 96/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3360 - val_loss: 0.3197\n",
      "Epoch 97/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3357 - val_loss: 0.3196\n",
      "Epoch 98/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3354 - val_loss: 0.3191\n",
      "Epoch 99/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3358 - val_loss: 0.3213\n",
      "Epoch 100/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3355 - val_loss: 0.3181\n",
      "Epoch 101/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3346 - val_loss: 0.3184\n",
      "Epoch 102/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3336 - val_loss: 0.3185\n",
      "Epoch 103/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3334 - val_loss: 0.3179\n",
      "Epoch 104/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3330 - val_loss: 0.3196\n",
      "Epoch 105/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3331 - val_loss: 0.3189\n",
      "Epoch 106/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3326 - val_loss: 0.3180\n",
      "Epoch 107/1000\n",
      "1791/1791 [==============================] - 0s 23us/sample - loss: 0.3329 - val_loss: 0.3182\n",
      "Epoch 108/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3319 - val_loss: 0.3187\n",
      "Epoch 109/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3319 - val_loss: 0.3172\n",
      "Epoch 110/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3329 - val_loss: 0.3203\n",
      "Epoch 111/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3317 - val_loss: 0.3173\n",
      "Epoch 112/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3310 - val_loss: 0.3184\n",
      "Epoch 113/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3309 - val_loss: 0.3164\n",
      "Epoch 114/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3308 - val_loss: 0.3179\n",
      "Epoch 115/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3302 - val_loss: 0.3164\n",
      "Epoch 116/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.3302 - val_loss: 0.3172\n",
      "Epoch 117/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3297 - val_loss: 0.3176\n",
      "Epoch 118/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3294 - val_loss: 0.3174\n",
      "Epoch 119/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3292 - val_loss: 0.3167\n",
      "Epoch 120/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3291 - val_loss: 0.3174\n",
      "Epoch 121/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3285 - val_loss: 0.3175\n",
      "Epoch 122/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3281 - val_loss: 0.3160\n",
      "Epoch 123/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3285 - val_loss: 0.3164\n",
      "Epoch 124/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3283 - val_loss: 0.3159\n",
      "Epoch 125/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3281 - val_loss: 0.3210\n",
      "Epoch 126/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3281 - val_loss: 0.3163\n",
      "Epoch 127/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3276 - val_loss: 0.3171\n",
      "Epoch 128/1000\n",
      "1791/1791 [==============================] - 0s 33us/sample - loss: 0.3277 - val_loss: 0.3163\n",
      "Epoch 129/1000\n",
      "1791/1791 [==============================] - 0s 38us/sample - loss: 0.3268 - val_loss: 0.3157\n",
      "Epoch 130/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3274 - val_loss: 0.3204\n",
      "Epoch 131/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3264 - val_loss: 0.3159\n",
      "Epoch 132/1000\n",
      "1791/1791 [==============================] - 0s 35us/sample - loss: 0.3271 - val_loss: 0.3186\n",
      "Epoch 133/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3286 - val_loss: 0.3159\n",
      "Epoch 134/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3283 - val_loss: 0.3209\n",
      "Epoch 135/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3266 - val_loss: 0.3153\n",
      "Epoch 136/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3258 - val_loss: 0.3176\n",
      "Epoch 137/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3264 - val_loss: 0.3176\n",
      "Epoch 138/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3256 - val_loss: 0.3159\n",
      "Epoch 139/1000\n",
      "1791/1791 [==============================] - 0s 43us/sample - loss: 0.3248 - val_loss: 0.3170\n",
      "Epoch 140/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3252 - val_loss: 0.3179\n",
      "Epoch 141/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3260 - val_loss: 0.3148\n",
      "Epoch 142/1000\n",
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3247 - val_loss: 0.3182\n",
      "Epoch 143/1000\n",
      "1791/1791 [==============================] - 0s 37us/sample - loss: 0.3236 - val_loss: 0.3158\n",
      "Epoch 144/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3240 - val_loss: 0.3164\n",
      "Epoch 145/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3245 - val_loss: 0.3187\n",
      "Epoch 146/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3243 - val_loss: 0.3178\n",
      "Epoch 147/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3243 - val_loss: 0.3149\n",
      "Epoch 148/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3239 - val_loss: 0.3184\n",
      "Epoch 149/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3228 - val_loss: 0.3149\n",
      "Epoch 150/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3231 - val_loss: 0.3175\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1791 [==============================] - 0s 32us/sample - loss: 0.3228 - val_loss: 0.3160\n",
      "Epoch 152/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3231 - val_loss: 0.3177\n",
      "Epoch 153/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3225 - val_loss: 0.3165\n",
      "Epoch 154/1000\n",
      "1791/1791 [==============================] - 0s 34us/sample - loss: 0.3224 - val_loss: 0.3183\n",
      "Epoch 155/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3227 - val_loss: 0.3167\n",
      "Epoch 156/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3217 - val_loss: 0.3170\n",
      "Epoch 157/1000\n",
      "1791/1791 [==============================] - 0s 26us/sample - loss: 0.3227 - val_loss: 0.3189\n",
      "Epoch 158/1000\n",
      "1791/1791 [==============================] - 0s 28us/sample - loss: 0.3225 - val_loss: 0.3190\n",
      "Epoch 159/1000\n",
      "1791/1791 [==============================] - 0s 25us/sample - loss: 0.3214 - val_loss: 0.3168\n",
      "Epoch 160/1000\n",
      "1791/1791 [==============================] - 0s 30us/sample - loss: 0.3222 - val_loss: 0.3176\n",
      "Epoch 161/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3216 - val_loss: 0.3177\n",
      "Epoch 162/1000\n",
      "1791/1791 [==============================] - 0s 36us/sample - loss: 0.3222 - val_loss: 0.3155\n",
      "Epoch 163/1000\n",
      "1791/1791 [==============================] - 0s 31us/sample - loss: 0.3213 - val_loss: 0.3179\n",
      "Epoch 164/1000\n",
      "1791/1791 [==============================] - 0s 29us/sample - loss: 0.3213 - val_loss: 0.3163\n",
      "Epoch 165/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3211 - val_loss: 0.3181\n",
      "Epoch 166/1000\n",
      "1791/1791 [==============================] - 0s 27us/sample - loss: 0.3206 - val_loss: 0.3167\n",
      "Epoch 00166: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17061a41ac8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=1000,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop],batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17061b79dc8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[327  22]\n",
      " [ 58 190]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       349\n",
      "           1       0.90      0.77      0.83       248\n",
      "\n",
      "    accuracy                           0.87       597\n",
      "   macro avg       0.87      0.85      0.86       597\n",
      "weighted avg       0.87      0.87      0.86       597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_ANN_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = df.drop('Cancer Positive',axis=1).iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                    31.000000\n",
       "BMI                    10.204207\n",
       "BreastFeeding           1.000000\n",
       "Marital Status          1.000000\n",
       "Alcohol                 0.000000\n",
       "Smoking                 0.000000\n",
       "BreastCancerHistory     0.000000\n",
       "Age at firstPeriod     12.000000\n",
       "MenstrualCycle          1.000000\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = scaler.transform(new_data.values.reshape(-1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28125   , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30769231, 1.        ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00409736]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40973578579723835"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(new_data)[0][0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "later_model = load_model('final_ANN_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00409736]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "later_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
